{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching\n",
    "\n",
    "\n",
    "### Overview\n",
    "Understanding Spark caching\n",
    "\n",
    "\n",
    "\n",
    "### STEP 1: Generate some large data\n",
    "\n",
    "Under `data/twinkle` directory we have created some large data files for you. \n",
    "\n",
    "You can generate more data if you'd like.\n",
    "```bash\n",
    "    $    cd data/twinkle\n",
    "    $    ./create-data-files.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    # initialize Spark Session\n",
    "    import os\n",
    "    import sys\n",
    "    top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "    if top_dir not in sys.path:\n",
    "        sys.path.append(top_dir)\n",
    "\n",
    "    from init_spark import init_spark\n",
    "    spark = init_spark()\n",
    "\n",
    "print('Spark UI running on port ' + spark.sparkContext.uiWebUrl.split(':')[2])\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Log Level\n",
    "Also set the logging level to INFO (so Spark will print out job execution times on console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"INFO\")\n",
    "print(\"set log level to INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Recording Caching times\n",
    "Download and inspect the Excel worksheet : [caching-worksheet](caching-worksheet.xlsx).   \n",
    "We are going to fill in the values here to understand how caching performs.\n",
    "\n",
    "\n",
    "## STEP 4: Load Data\n",
    "\n",
    "Load a big file (e.g 500M.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data_location = 'data/twinkle/500M.data'\n",
    "data_location = 's3://elephantscale-public/data/text/twinkle/100M.data'\n",
    "# data_location = 'https://elephantscale-public.s3.amazonaws.com/data/text/twinkle/100M.data'\n",
    "\n",
    "f = spark.read.text(data_location)\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Count the number of lines in this file**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.count()\n",
    "# output might look like\n",
    "# Job 1 finished: count at <console>:30, took __3.792822__ s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.count()\n",
    "f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Do the same count() operation a few times until the execution time 'stablizes'**  \n",
    "**=> Record the time in spreadsheet.**  \n",
    "**=> Can you explain the behavior of count() execution time ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## STEP 5:  Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Run the `count()` again. Notice the time.   Can you explain this behavior ?  :-)** \n",
    "\n",
    "**=> Run count() a few more times and note the execution times.**  \n",
    "**=> Record the time in spreadsheet.**  \n",
    "**=> Do the timings make sense?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.count()\n",
    "f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6:  Understanding Cache storage\n",
    "\n",
    "Go to spark shell UI @ port 4040  \n",
    "**=> Inspect 'storage' tab**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group discussion\n",
    "\n",
    "* mechanics of caching\n",
    "* implications of caching vs memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "* [Understanding Spark Caching by Sujee Maniyam](http://sujee.net/2015/01/22/understanding-spark-caching/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
